{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c955312c-6512-4acc-87de-341a2ece9dab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "from pprint import pprint\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "TRACKING_URI=\"http://mlflow.mlnow.frenoid.com:30080/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c4a153c-a122-4c8d-b340-4665d3c9d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credentials are stored in ~/.mlflow/credentials\n",
    "client = MlflowClient(tracking_uri=TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "facaa6e1-7970-4ce3-9fb3-a7d306d051b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1708652897569, experiment_id='0', last_update_time=1708652897569, lifecycle_stage='active', name='Default', tags={}>]\n"
     ]
    }
   ],
   "source": [
    "all_experiments = client.search_experiments()\n",
    "\n",
    "print(all_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3253c71a-31f8-4ee7-becd-9fe123938d37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lifecycle_stage': 'active', 'name': 'Default'}\n"
     ]
    }
   ],
   "source": [
    "default_experiment = [\n",
    "     {\"name\": experiment.name, \"lifecycle_stage\": experiment.lifecycle_stage} for experiment in all_experiments if experiment.name == \"Default\"   \n",
    "][0]\n",
    "\n",
    "pprint(default_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4fa4edd-3724-4d97-8184-89019964a68d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_description = (\n",
    "     \"This is the grocery forecasting project. \"\n",
    "     \"This experiment contains the produce models for apples. \"\n",
    ")\n",
    "\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"grocery-forecasting\",\n",
    "    \"store_dept\": \"produce\",\n",
    "    \"team\": \"stores-ml\",\n",
    "    \"project_quarter\": \"Q3-2023\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "produce_apples_experiment = client.create_experiment(\n",
    "    name=\"Apple_Models\", tags=experiment_tags   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d0a6edf-1494-4010-ae16-91f28324ad39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_experiment_id': '1', '_name': 'Apple_Models', '_artifact_location': 'mlflow-artifacts:/1', '_lifecycle_stage': 'active', '_tags': {'project_name': 'grocery-forecasting', 'store_dept': 'produce', 'team': 'stores-ml', 'project_quarter': 'Q3-2023', 'mlflow.note.content': 'This is the grocery forecasting project. This experiment contains the produce models for apples. '}, '_creation_time': 1708783225351, '_last_update_time': 1708783225351}\n",
      "\n",
      "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1708783225351, experiment_id='1', last_update_time=1708783225351, lifecycle_stage='active', name='Apple_Models', tags={'mlflow.note.content': 'This is the grocery forecasting project. This '\n",
      "                        'experiment contains the produce models for apples. ',\n",
      " 'project_name': 'grocery-forecasting',\n",
      " 'project_quarter': 'Q3-2023',\n",
      " 'store_dept': 'produce',\n",
      " 'team': 'stores-ml'}>\n"
     ]
    }
   ],
   "source": [
    "# Use search_experiments() to search on project_name tag key\n",
    "apples_experiment = client.search_experiments(\n",
    "    filter_string=\"tags.`project_name` = 'grocery-forecasting'\"\n",
    ")\n",
    "\n",
    "print(vars(apples_experiment[0]))\n",
    "print()\n",
    "print(apples_experiment[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea951d1f-8869-4cdd-983f-107200053570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def generate_apple_sales_data_with_promo_adjustment(\n",
    "    base_demand: int = 1000, n_rows: int = 5000\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a synthetic dataset for predicting apple sales demand with seasonality\n",
    "    and inflation.\n",
    "\n",
    "    This function creates a pandas DataFrame with features relevant to apple sales.\n",
    "    The features include date, average_temperature, rainfall, weekend flag, holiday flag,\n",
    "    promotional flag, price_per_kg, and the previous day's demand. The target variable,\n",
    "    'demand', is generated based on a combination of these features with some added noise.\n",
    "\n",
    "    Args:\n",
    "        base_demand (int, optional): Base demand for apples. Defaults to 1000.\n",
    "        n_rows (int, optional): Number of rows (days) of data to generate. Defaults to 5000.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with features and target variable for apple sales prediction.\n",
    "\n",
    "    Example:\n",
    "        >>> df = generate_apple_sales_data_with_seasonality(base_demand=1200, n_rows=6000)\n",
    "        >>> df.head()\n",
    "    \"\"\"\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(9999)\n",
    "\n",
    "    # Create date range\n",
    "    dates = [datetime.now() - timedelta(days=i) for i in range(n_rows)]\n",
    "    dates.reverse()\n",
    "\n",
    "    # Generate features\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"date\": dates,\n",
    "            \"average_temperature\": np.random.uniform(10, 35, n_rows),\n",
    "            \"rainfall\": np.random.exponential(5, n_rows),\n",
    "            \"weekend\": [(date.weekday() >= 5) * 1 for date in dates],\n",
    "            \"holiday\": np.random.choice([0, 1], n_rows, p=[0.97, 0.03]),\n",
    "            \"price_per_kg\": np.random.uniform(0.5, 3, n_rows),\n",
    "            \"month\": [date.month for date in dates],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Introduce inflation over time (years)\n",
    "    df[\"inflation_multiplier\"] = (\n",
    "        1 + (df[\"date\"].dt.year - df[\"date\"].dt.year.min()) * 0.03\n",
    "    )\n",
    "\n",
    "    # Incorporate seasonality due to apple harvests\n",
    "    df[\"harvest_effect\"] = np.sin(2 * np.pi * (df[\"month\"] - 3) / 12) + np.sin(\n",
    "        2 * np.pi * (df[\"month\"] - 9) / 12\n",
    "    )\n",
    "\n",
    "    # Modify the price_per_kg based on harvest effect\n",
    "    df[\"price_per_kg\"] = df[\"price_per_kg\"] - df[\"harvest_effect\"] * 0.5\n",
    "\n",
    "    # Adjust promo periods to coincide with periods lagging peak harvest by 1 month\n",
    "    peak_months = [4, 10]  # months following the peak availability\n",
    "    df[\"promo\"] = np.where(\n",
    "        df[\"month\"].isin(peak_months),\n",
    "        1,\n",
    "        np.random.choice([0, 1], n_rows, p=[0.85, 0.15]),\n",
    "    )\n",
    "\n",
    "    # Generate target variable based on features\n",
    "    base_price_effect = -df[\"price_per_kg\"] * 50\n",
    "    seasonality_effect = df[\"harvest_effect\"] * 50\n",
    "    promo_effect = df[\"promo\"] * 200\n",
    "\n",
    "    df[\"demand\"] = (\n",
    "        base_demand\n",
    "        + base_price_effect\n",
    "        + seasonality_effect\n",
    "        + promo_effect\n",
    "        + df[\"weekend\"] * 300\n",
    "        + np.random.normal(0, 50, n_rows)\n",
    "    ) * df[\n",
    "        \"inflation_multiplier\"\n",
    "    ]  # adding random noise\n",
    "\n",
    "    # Add previous day's demand\n",
    "    df[\"previous_days_demand\"] = df[\"demand\"].shift(1)\n",
    "    df[\"previous_days_demand\"].fillna(\n",
    "        method=\"bfill\", inplace=True\n",
    "    )  # fill the first row\n",
    "\n",
    "    # Drop temporary columns\n",
    "    df.drop(columns=[\"inflation_multiplier\", \"harvest_effect\", \"month\"], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b84ddbfc-cba5-4c65-a5d5-523916c7d009",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20393/3859398416.py:89: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[\"previous_days_demand\"].fillna(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>weekend</th>\n",
       "      <th>holiday</th>\n",
       "      <th>price_per_kg</th>\n",
       "      <th>promo</th>\n",
       "      <th>demand</th>\n",
       "      <th>previous_days_demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>2024-02-05 15:30:49.992394</td>\n",
       "      <td>34.130183</td>\n",
       "      <td>1.454065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.449177</td>\n",
       "      <td>0</td>\n",
       "      <td>999.306290</td>\n",
       "      <td>1356.418398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>2024-02-06 15:30:49.992393</td>\n",
       "      <td>32.353643</td>\n",
       "      <td>9.462859</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.856503</td>\n",
       "      <td>0</td>\n",
       "      <td>842.129427</td>\n",
       "      <td>999.306290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>2024-02-07 15:30:49.992393</td>\n",
       "      <td>18.816833</td>\n",
       "      <td>0.391470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.326429</td>\n",
       "      <td>0</td>\n",
       "      <td>990.616709</td>\n",
       "      <td>842.129427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>2024-02-08 15:30:49.992392</td>\n",
       "      <td>34.533012</td>\n",
       "      <td>2.120477</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970131</td>\n",
       "      <td>0</td>\n",
       "      <td>1068.802075</td>\n",
       "      <td>990.616709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>2024-02-09 15:30:49.992392</td>\n",
       "      <td>23.057202</td>\n",
       "      <td>2.365705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.049931</td>\n",
       "      <td>0</td>\n",
       "      <td>1019.486305</td>\n",
       "      <td>1068.802075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>2024-02-10 15:30:49.992391</td>\n",
       "      <td>34.810165</td>\n",
       "      <td>3.089005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.035149</td>\n",
       "      <td>0</td>\n",
       "      <td>1329.564672</td>\n",
       "      <td>1019.486305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>2024-02-11 15:30:49.992391</td>\n",
       "      <td>29.208905</td>\n",
       "      <td>3.673292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.518098</td>\n",
       "      <td>0</td>\n",
       "      <td>1413.143402</td>\n",
       "      <td>1329.564672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>2024-02-12 15:30:49.992390</td>\n",
       "      <td>16.428676</td>\n",
       "      <td>4.077782</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.268979</td>\n",
       "      <td>0</td>\n",
       "      <td>1093.207186</td>\n",
       "      <td>1413.143402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>2024-02-13 15:30:49.992389</td>\n",
       "      <td>32.067512</td>\n",
       "      <td>2.734454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.762317</td>\n",
       "      <td>0</td>\n",
       "      <td>1069.939894</td>\n",
       "      <td>1093.207186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>2024-02-14 15:30:49.992389</td>\n",
       "      <td>31.938203</td>\n",
       "      <td>13.883486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.153301</td>\n",
       "      <td>0</td>\n",
       "      <td>994.409540</td>\n",
       "      <td>1069.939894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>2024-02-15 15:30:49.992388</td>\n",
       "      <td>18.024055</td>\n",
       "      <td>7.544061</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.610703</td>\n",
       "      <td>0</td>\n",
       "      <td>1078.323183</td>\n",
       "      <td>994.409540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>2024-02-16 15:30:49.992387</td>\n",
       "      <td>20.681067</td>\n",
       "      <td>18.820490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.533488</td>\n",
       "      <td>0</td>\n",
       "      <td>1001.499120</td>\n",
       "      <td>1078.323183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>2024-02-17 15:30:49.992386</td>\n",
       "      <td>16.010132</td>\n",
       "      <td>7.705941</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.632498</td>\n",
       "      <td>1</td>\n",
       "      <td>1548.922141</td>\n",
       "      <td>1001.499120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>2024-02-18 15:30:49.992384</td>\n",
       "      <td>18.766455</td>\n",
       "      <td>6.274840</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.806554</td>\n",
       "      <td>0</td>\n",
       "      <td>1283.412724</td>\n",
       "      <td>1548.922141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2024-02-19 15:30:49.992384</td>\n",
       "      <td>27.948793</td>\n",
       "      <td>23.705246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.829464</td>\n",
       "      <td>0</td>\n",
       "      <td>1090.592622</td>\n",
       "      <td>1283.412724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2024-02-20 15:30:49.992383</td>\n",
       "      <td>28.661072</td>\n",
       "      <td>10.329865</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.290591</td>\n",
       "      <td>0</td>\n",
       "      <td>936.465043</td>\n",
       "      <td>1090.592622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2024-02-21 15:30:49.992382</td>\n",
       "      <td>10.821693</td>\n",
       "      <td>3.575645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.897473</td>\n",
       "      <td>0</td>\n",
       "      <td>1016.336362</td>\n",
       "      <td>936.465043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2024-02-22 15:30:49.992381</td>\n",
       "      <td>21.108560</td>\n",
       "      <td>6.221089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.093864</td>\n",
       "      <td>0</td>\n",
       "      <td>1063.698477</td>\n",
       "      <td>1016.336362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2024-02-23 15:30:49.992380</td>\n",
       "      <td>29.451301</td>\n",
       "      <td>5.021463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.493085</td>\n",
       "      <td>0</td>\n",
       "      <td>979.255235</td>\n",
       "      <td>1063.698477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2024-02-24 15:30:49.992376</td>\n",
       "      <td>19.261458</td>\n",
       "      <td>0.438381</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.610422</td>\n",
       "      <td>0</td>\n",
       "      <td>1207.188828</td>\n",
       "      <td>979.255235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  average_temperature   rainfall  weekend  \\\n",
       "980 2024-02-05 15:30:49.992394            34.130183   1.454065        0   \n",
       "981 2024-02-06 15:30:49.992393            32.353643   9.462859        0   \n",
       "982 2024-02-07 15:30:49.992393            18.816833   0.391470        0   \n",
       "983 2024-02-08 15:30:49.992392            34.533012   2.120477        0   \n",
       "984 2024-02-09 15:30:49.992392            23.057202   2.365705        0   \n",
       "985 2024-02-10 15:30:49.992391            34.810165   3.089005        1   \n",
       "986 2024-02-11 15:30:49.992391            29.208905   3.673292        1   \n",
       "987 2024-02-12 15:30:49.992390            16.428676   4.077782        0   \n",
       "988 2024-02-13 15:30:49.992389            32.067512   2.734454        0   \n",
       "989 2024-02-14 15:30:49.992389            31.938203  13.883486        0   \n",
       "990 2024-02-15 15:30:49.992388            18.024055   7.544061        0   \n",
       "991 2024-02-16 15:30:49.992387            20.681067  18.820490        0   \n",
       "992 2024-02-17 15:30:49.992386            16.010132   7.705941        1   \n",
       "993 2024-02-18 15:30:49.992384            18.766455   6.274840        1   \n",
       "994 2024-02-19 15:30:49.992384            27.948793  23.705246        0   \n",
       "995 2024-02-20 15:30:49.992383            28.661072  10.329865        0   \n",
       "996 2024-02-21 15:30:49.992382            10.821693   3.575645        0   \n",
       "997 2024-02-22 15:30:49.992381            21.108560   6.221089        0   \n",
       "998 2024-02-23 15:30:49.992380            29.451301   5.021463        0   \n",
       "999 2024-02-24 15:30:49.992376            19.261458   0.438381        1   \n",
       "\n",
       "     holiday  price_per_kg  promo       demand  previous_days_demand  \n",
       "980        0      1.449177      0   999.306290           1356.418398  \n",
       "981        0      2.856503      0   842.129427            999.306290  \n",
       "982        0      1.326429      0   990.616709            842.129427  \n",
       "983        0      0.970131      0  1068.802075            990.616709  \n",
       "984        0      1.049931      0  1019.486305           1068.802075  \n",
       "985        0      2.035149      0  1329.564672           1019.486305  \n",
       "986        0      2.518098      0  1413.143402           1329.564672  \n",
       "987        0      1.268979      0  1093.207186           1413.143402  \n",
       "988        0      0.762317      0  1069.939894           1093.207186  \n",
       "989        0      1.153301      0   994.409540           1069.939894  \n",
       "990        0      0.610703      0  1078.323183            994.409540  \n",
       "991        0      1.533488      0  1001.499120           1078.323183  \n",
       "992        0      1.632498      1  1548.922141           1001.499120  \n",
       "993        0      2.806554      0  1283.412724           1548.922141  \n",
       "994        0      0.829464      0  1090.592622           1283.412724  \n",
       "995        0      2.290591      0   936.465043           1090.592622  \n",
       "996        0      0.897473      0  1016.336362            936.465043  \n",
       "997        0      1.093864      0  1063.698477           1016.336362  \n",
       "998        0      2.493085      0   979.255235           1063.698477  \n",
       "999        0      2.610422      0  1207.188828            979.255235  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the dataset!\n",
    "\n",
    "data = generate_apple_sales_data_with_promo_adjustment(base_demand=1_000, n_rows=1_000)\n",
    "\n",
    "data[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d15e2e69-fd81-4b0d-9b94-b76a066a3f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0836405b-94b7-43f8-a8f0-821ff293bf52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8442747b-b3d9-4aed-968d-ff6e0310ab1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the current active experiment to \"Apple_Models\" experiment and returns the experiment metadata\n",
    "apple_experiment = mlflow.set_experiment(\"Apple_Models\")\n",
    "\n",
    "# Define a run name for this iteration of training, otherwise a unique name will be auto-generated for your run\n",
    "run_name = \"apples_rf_test\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to\n",
    "artifact_path = \"rf_apples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e231f142-7f01-4b5d-ab7c-aab00c1662bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3-11/lib/python3.11/site-packages/mlflow/models/signature.py:358: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  input_schema = _infer_schema(input_example)\n",
      "/opt/conda/envs/python3-11/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features and target and drop irrelevant date field and target field\n",
    "X = data.drop(columns=[\"date\", \"demand\"])\n",
    "y = data[\"demand\"]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"min_samples_leaf\": 4,\n",
    "    \"bootstrap\": True,\n",
    "    \"oob_score\": False,\n",
    "    \"random_state\": 888,\n",
    "}\n",
    "\n",
    "# Train the RandomForestRegressor\n",
    "rf = RandomForestRegressor(**params)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "# Calculate error metrics\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "# Assemble the metrics we're going to write into a collection\n",
    "metrics = {\"mae\": mae, \"mse\": mse, \"rmse\": rmse, \"r2\": r2}\n",
    "\n",
    "# Initiate the MLFlow run context\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=rf, input_example=X_val, artifact_path=artifact_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3771d6-ada9-4c59-a9f7-841d327b24c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4",
   "language": "python",
   "name": "python3-11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
